# -*- coding: utf-8 -*-
"""Prueba_bancolombia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o-V1TPtxFyS58mHz8bj9jZ2gf7BhKtFx
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

from bs4 import BeautifulSoup
import requests

#hago la consulta a la pagina y lo guardo como un archivo txt y luego lo convierto a html con Beautifulsoup
response = requests.get("https://github.com/samir2901/Data-Analysis-with-Python-1/blob/a059b8152821f0b24cddc7ebc1604eb380dd6e8a/Lemonade.csv")
txt = response.text
soup = BeautifulSoup(txt, 'html.parser')
#busco el tag que pertenezca a table y lo guardo en la variable 'table'
table = soup.find("table")

#creo un diccionario donde guardare los encabezados de la tabla
d ={}

# creo una lista con los encabezados y luego le asigno esos encabezados como llaves al diccionario y como valor paso listas vacias que llenare luego
titulo = [th.get_text() for th in table.find("tr").find_all("th")]
titulo
for i in titulo:
  d.setdefault(i, [])


# con este for recorro las filas de la tabla
for row in table.find_all("tr"):
   
   # Creo una lista donde guardo los valores de esa fila   
   valor = [td.get_text() for td in row.find_all("td") if td.get_text() != '']
   
   #con este for recorro las listas 'valor' y 'llaves' al mismo tiempo y agrego el valor a la lista de su respectiva llave
   for llave, valor in zip(titulo,valor):     
      d[llave].append(valor)

# convierto el diccionario en una dataframe y lo guardo en la varibale data
data = pd.DataFrame(data=d)

data

#Miramos tipos de datos de nuestras columnas y cantidad de datos faltantes
data.info()

"""Al analizar la info de los datos vemos que hay 365 filas y 7 columnas donde todas tienen como tipod de dato 'object'"""

#cambiamos nuestros tipos de datos de las columnas, ya que todos los tomo como texto 
data[['Temperature', 'Rainfall', 'Flyers', 'Price','Sales']] = data[['Temperature', 'Rainfall', 'Flyers', 'Price','Sales']].astype(float)
data['Date'] = pd.to_datetime(data['Date'], yearfirst=True)
print(data.info())
data

print(data.describe(),'\n\n')
print('Asimetria de los datos:\n\n',data.skew())

"""* Inicialmente podemos ver como las columnas Temperature y Flyers son las 
columnas con los valores de desviacion estandar mas altos con: 16.196 y 13.178 respectivamente. Y contrastar esto con sus valores minimos, maximos y el promedio nos damos una idea sobre lo dispersos que se encuentran.

* Para las columnas 'Price' y 'Rainfall' podemos ver como los valores maximos estan bastante alejados tanto de los valores de sus cuartiles como de su promedio, lo que nos da una idea de que podemos encontrar fuertes valores atipicos en estas columnas.
"""

#Creamos una funcion que nos divide el dataframe en nuemricos y objects
def divideFeatures(df):
    numerical_features = df.select_dtypes(include=[np.number])
    categorical_features = df.select_dtypes(include=[np.object])
    return numerical_features, categorical_features

cont_features, cat_features = divideFeatures(data)

fig = plt.figure(figsize=(10,8))
for i in range(len(cont_features.columns)):
    fig.add_subplot(2, 3, i+1)
    sns.boxplot(y=cont_features.iloc[:,i])
plt.tight_layout()
plt.show()

"""Aqui podemos ver como encontramos valores atipicos en 4 de las 5 columnas numericas. Donde:

*   Encontramos varios valores atipicos fuertes en las columnas 'Rainfall' y 'Price'. Especial mente en price que vemos como aplana el grafico de cajas en el cual estan aproximadamente el 95% de los datos.



"""

fig = plt.figure(figsize=(10,8))
for i in range(len(cont_features.columns)):
    fig.add_subplot(2, 3, i+1)
    sns.distplot(cont_features.iloc[:,i])    
plt.tight_layout()
plt.show();

"""Al mirar las distribuciones para las columnas de dato numerico, encontramos:

* las columnas Temperature, Flyers y Sales tienen una distribucion normal.

* Para la columna Rainfall encontramos unos datos con un sesgo fuerte hacia la derecha lo cual podemos corroborar en la grafica de cajas anterior y en los valores de asimetria.

* Para la columna Price podemos ver que aunque es una columna numerica es discreta ya que tiene solo 2 posibles valores.
"""

plt.title('Cantidad de registros por precio')
data.Price.value_counts().plot(kind='bar')
plt.xlabel('Precio')
plt.ylabel('Cantidad')
plt.show();

data.Price.value_counts(normalize=True)

"""* En la grafica anterior podemos ver como hay un desbalanceo en las clases para la columna Price y vemos como el precio de 0.3 corresponde aproximadamente al 83%. Lo que nos da a pensar si talvez la muestra se encuentra sesgada y para futuros analisis se debe tener encuenta esta condicion."""

fig = plt.figure(figsize=(6,6))
for i in range(len(cat_features.columns)):
    fig.add_subplot(1, 1, i+1)
    sns.countplot(cat_features.iloc[:,i])  
plt.xticks(rotation=90)
plt.tight_layout()
plt.show();

"""Encontramos que la cantidad de dias de la semana que hay los datos esta muy pareja."""

plt.figure(figsize=(7,7))
plt.title('Correlacion de los datos')
sns.heatmap(data=data.corr(),vmin=-1, vmax=1, annot=True, cmap='coolwarm');

"""* Encontramos una fuerte correlacion positiva entre Sales y Temperatura, lo que nos dice que cuando la temperatura sube las ventas tambien.

* Encontramos una correlacion negativa fuerte entre Sales y RainFall, lo que nso dice que entre mas vale Rainfall Sales baja

* tambien encontramos una correlacion negativa fuerte entre Temperatura y Rainfall, lo cual nos dice que cuando temperatura sube rainfall baja.

* tambien podemos ver unas correlacion positivas interesantes de Flyers con Temperatura y Sales. Lo que nos dice que cuando Flyers sube las otras dos tambien lo hacen.
"""

#Organizamos los datos por fecha de menor a mayor y resetamos el index
data.sort_values(by='Date',ascending=True,ignore_index=True,inplace=True)
data

plt.figure(figsize=(12,8))
plt.plot(data.Date, data.Sales)
plt.xlabel('Fecha')
plt.ylabel('Sales')
plt.show();

"""* Podemos ver como los picos mas altos en ventas se dan al inicio de cada mes. excepto en los meses de junio y julio.

* Donde la venta mas baja se dio en el ultimo mes de año.
"""

plt.figure(figsize=(12,8))
plt.scatter(data.Date, data.Sales, c=data.Price, cmap='coolwarm')
plt.xlabel('Fecha')
plt.ylabel('Sales')
plt.show();

"""* De este grafico podemos concluir que las ventas estan mas agrupadas despues de cada pico de Sales.

* Podemos ver un patron donde desde enero hasta Julio aproximadamente tienden a subir las ventas  y de julio a diciembre tienden a bajar.

* Podemos observar que se registro una mayor frecuencia de Sales en los meses de julio y agosto.
"""

sns.pairplot(data=data, hue='Price');

"""Del siguiente grafico podemos concluir:

*   Solo hay Sales con Price de 0.5 cuando la Temperatura es superior a 60 C° aproximadamente.
*   Solo hay Sales con Price de 0.5 cuando Rainfall es menor o igual a 0.75 aproximadamente.
* Cuando se hay Sales com Price de 0.5, Sales tiende a tomas valores aproximadamente de 30 en adelante.

"""

#Se convirtio el dataframe en un archivo .csv
data.to_csv('data.csv')